{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = 500000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load episode set $E$ with the users that retweeted each original tweet in the trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = pickle.load(open(\"./extracted/E\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in E:\n",
    "    E[tweet] = list(dict.fromkeys(E[tweet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pickle.load(open(\"./extracted/D\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the set of original tweets denoted by $S$. \n",
    "\n",
    "The set of original tweets is denoted by $S$, where $S$ = S is the total number of original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pickle.load(open(\"./extracted/S\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $U$ set xith unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = pickle.load(open(\"./extracted/U\"+ str(lines) + \".p\", \"rb\"))\n",
    "U = list(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $M_{ij}$ variables that count number of episodes where the ordered pair (i,j) appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pickle.load(open(\"./extracted/M\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $Q_{ij}$ results for the ordered pair (i,j) derived from the consrained algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = pickle.load(open(\"./extracted/Q_constrained_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $s_{ij}$ derived from the consrained algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.load(open(\"./extracted/s_constrained_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $k_{ij}$ derived from Saito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pickle.load(open(\"./extracted/k_saito_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $Q_{ij}$ derived from Newman's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_newman = pickle.load(open(\"./extracted/Q_newman_\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(obj):\n",
    "    if type(obj) == list:\n",
    "        return [l for L in obj for l in L]\n",
    "    if type(obj) == dict:\n",
    "        return [l for i in obj for l in obj[i].values()]\n",
    "    if type(obj) == defaultdict:\n",
    "        return [l for i in obj for l in obj[i].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain_graph(U,D):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for tweet in D:\n",
    "        for time in D[tweet]:\n",
    "            ind = list(D[tweet].keys()).index(time)\n",
    "            if ind+1==len(D[tweet]): break\n",
    "            next_time = list(D[tweet].keys())[ind+1]\n",
    "            for u1 in D[tweet][time]:\n",
    "                for u2 in D[tweet][next_time]:\n",
    "                    G.add_edge(u1,u2)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_saito_graph(U,k):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "\n",
    "    for i in k:\n",
    "        for j in k[i]:\n",
    "            if k[i][j] > 0.5:\n",
    "                G.add_edge(i,j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_star_graph(U,E):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for s in E:\n",
    "        for j in E[s][1:]:\n",
    "            G.add_edge(E[s][0],j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_our_graph(U,Q):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for i in Q:\n",
    "        for j in Q[i]:\n",
    "            if Q[i][j] > 0.5:\n",
    "                G.add_edge(i,j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_newman_graph(U,Q):\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(U)\n",
    "    for i in Q:\n",
    "        for j in Q[i]:\n",
    "            if Q[i][j] > 0.5:\n",
    "                G.add_edge(i,j)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_check(E, Q):\n",
    "    '''\n",
    "    Function that checks feasibility of graph.\n",
    "\n",
    "    '''\n",
    "    retweets = 0 # minimum existing edges\n",
    "    infeasible_episodes = 0 \n",
    "    total_feasible_edges = []\n",
    "    total_inf = 0 \n",
    "    for s in E:\n",
    "        feasible_edges = 0 \n",
    "        for j in E[s]:\n",
    "            indx = E[s].index(j)\n",
    "            if indx!=0:\n",
    "                u_before = E[s][:indx]\n",
    "                for i in u_before: \n",
    "                    if i in Q and j in Q[i] and Q[i][j] > 0.5:\n",
    "                        feasible_edges +=1\n",
    "                        total_feasible_edges.append((i,j))\n",
    "\n",
    "        infeasible = (len(E[s]) - 1) - feasible_edges\n",
    "        if infeasible > 0:\n",
    "            total_inf+=infeasible\n",
    "            infeasible_episodes+=1\n",
    "        retweets += len(E[s])-1\n",
    "        total_feasible_edges = list(set(total_feasible_edges))\n",
    "    return infeasible_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_path(E, U, Q, k, graph_type):\n",
    "    max_l = 0\n",
    "    max_path = 0\n",
    "    if graph_type=='ours' or graph_type=='newman':    \n",
    "        for s in E:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(U)\n",
    "            for j in E[s][1:]:\n",
    "                    indx = E[s].index(j)\n",
    "                    u_before = E[s][:indx]\n",
    "                    for i in u_before: \n",
    "                            if j in Q[i] and Q[i][j] > 0.5:\n",
    "                                G.add_edge(i,j)\n",
    "            if len(nx.dag_longest_path(G))>max_l: \n",
    "                max_l = len(nx.dag_longest_path(G))\n",
    "                max_path = nx.dag_longest_path(G)\n",
    "                \n",
    "    if graph_type=='star':\n",
    "        for s in E:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(U)\n",
    "            for j in E[s][1:]:\n",
    "                G.add_edge(E[s][0],j)\n",
    "            if len(nx.dag_longest_path(G))>max_l: \n",
    "                max_l = len(nx.dag_longest_path(G))\n",
    "                max_path = nx.dag_longest_path(G)\n",
    "                \n",
    "    if graph_type=='saito':    \n",
    "        for s in E:\n",
    "            G = nx.DiGraph()\n",
    "            G.add_nodes_from(U)\n",
    "            for j in E[s][1:]:\n",
    "                    indx = E[s].index(j)\n",
    "                    u_before = E[s][:indx]\n",
    "                    for i in u_before: \n",
    "                            if j in k[i] and k[i][j] > 0.5:\n",
    "                                G.add_edge(i,j)\n",
    "\n",
    "            if len(nx.dag_longest_path(G))>max_l: \n",
    "                max_l = len(nx.dag_longest_path(G))\n",
    "                max_path = nx.dag_longest_path(G)\n",
    "    return max_l, max_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tweetgraph(s, E, S, Q, k, pos, graph_type):\n",
    "        G = nx.DiGraph()\n",
    "        if graph_type=='ours' or graph_type=='newman':\n",
    "            t = 0\n",
    "            for j in E[s][1:]:\n",
    "                G.add_node(j)\n",
    "                indx = E[s].index(j)\n",
    "                u_before = E[s][:indx]\n",
    "                for i in u_before: \n",
    "                        G.add_node(i)\n",
    "                        if j in Q[i] and Q[i][j] > 0.5:\n",
    "                            G.add_edge(i,j, label=f'{t}')\n",
    "                            t+=1\n",
    "        elif graph_type=='star':\n",
    "            G.add_node(E[s][0])\n",
    "            for j in E[s][1:]:\n",
    "                    G.add_edge(E[s][0],j)\n",
    "                    G.add_node(j)\n",
    "        elif graph_type=='saito':\n",
    "            t = 0\n",
    "            for j in E[s][1:]:\n",
    "                G.add_node(j)\n",
    "                indx = E[s].index(j)\n",
    "                u_before = E[s][:indx]\n",
    "                for i in u_before: \n",
    "                        G.add_node(i)\n",
    "                        if j in k[i] and k[i][j] > 0.5:\n",
    "                            G.add_edge(i,j, label=f'{t}')\n",
    "                            t+=1\n",
    "        elif graph_type=='chain':\n",
    "            for time in D[s]:\n",
    "                ind = list(D[tweet].keys()).index(time)\n",
    "                if ind+1==len(D[tweet]): break\n",
    "                next_time = list(D[tweet].keys())[ind+1]\n",
    "                for u1 in D[tweet][time]:\n",
    "                    for u2 in D[tweet][next_time]:\n",
    "                        G.add_edge(u1,u2)\n",
    "        color_map = []\n",
    "        cmap = plt.get_cmap('Greens')\n",
    "        for node in G:\n",
    "            if node == S[tweet]:\n",
    "                color_map.append('green')\n",
    "            else:\n",
    "                color_map.append('yellow')\n",
    "        pos = nx.spring_layout(G)        \n",
    "        nx.draw_networkx_nodes(G, pos, node_color = color_map, cmap=plt.get_cmap('jet'), node_size = 300)\n",
    "        nx.draw_networkx_edges(G, pos, edge_color='r', arrows=True)\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "        if graph_type=='ours' or graph_type=='saito':\n",
    "            nx.draw_networkx_edge_labels(G, pos, font_size=8)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "## 1. number of infeasible episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "data['Graph Type with Lines: ' + str(lines)] = ['Ours','Saito','Star','Chain', 'Newman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_ep_ours = f_check(E, Q)\n",
    "inf_ep_saito = f_check(E, k)\n",
    "inf_ep_newman = f_check(E, Q_newman)\n",
    "data['Infeasible Episodes'] = [inf_ep_ours, inf_ep_saito, 0, 0, inf_ep_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_star = create_star_graph(U,E)\n",
    "G_ours = create_our_graph(U,Q)\n",
    "G_saito = create_saito_graph(U,k)\n",
    "G_newman = create_newman_graph(U,Q_newman)\n",
    "G_chain = create_chain_graph(U,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_ours = len(G_ours.edges())\n",
    "edges_saito = len(G_saito.edges())\n",
    "edges_star = len(G_star.edges())\n",
    "edges_chain = len(G_chain.edges())\n",
    "edges_newman = len(G_newman.edges())\n",
    "data['Number of edges'] = [edges_ours, edges_saito, edges_star, edges_chain, edges_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Average out degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "av_ours = sum(d[1] for d in G_ours.out_degree())/float(len(G_ours))\n",
    "av_saito = sum(d[1] for d in G_saito.out_degree())/float(len(G_saito))\n",
    "av_star = sum(d[1] for d in G_star.out_degree())/float(len(G_star))\n",
    "av_chain = sum(d[1] for d in G_chain.out_degree())/float(len(G_chain))\n",
    "av_newman = sum(d[1] for d in G_newman.out_degree())/float(len(G_newman))\n",
    "\n",
    "data['Average out degree'] = [av_ours, av_saito, av_star, av_chain, av_newman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = list(G_ours.out_degree())\n",
    "max_degree_our = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_saito.out_degree())\n",
    "max_degree_saito = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_star.out_degree())\n",
    "max_degree_star = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_chain.out_degree())\n",
    "max_degree_chain = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_newman.out_degree())\n",
    "max_degree_newman = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "data['Max out degree'] = [max_degree_our, max_degree_saito, max_degree_star, max_degree_chain, max_degree_newman]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_sequence = list(G_ours.in_degree())\n",
    "max_degree_our = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_saito.in_degree())\n",
    "max_degree_saito = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_star.in_degree())\n",
    "max_degree_star = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_chain.in_degree())\n",
    "max_degree_chain = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "degree_sequence = list(G_newman.in_degree())\n",
    "max_degree_newman = max(np.array(degree_sequence)[:,1])\n",
    "\n",
    "data['Max in degree'] = [max_degree_our, max_degree_saito, max_degree_star, max_degree_chain, max_degree_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph diameter\n",
    "\n",
    "The maximum among all the distances between a vertex to all other vertices is considered as the diameter of the Graph G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_sh_path(G, graph_type):\n",
    "    lst = dict(nx.all_pairs_shortest_path_length(G))\n",
    "    sum_lst = sum(lst[i][j] for i in lst for j in lst[i])\n",
    "    l_lst = sum(1 for i in lst for j in lst[i] if i!=j)\n",
    "    avg_spl = sum_lst/l_lst\n",
    "    diameter = [max(val.values()) for key, val in lst.items()]\n",
    "    diameter = max(diameter)\n",
    "    return avg_spl, diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ours, d_ours = avg_sh_path(G_ours, 'Ours')\n",
    "avg_saito, d_saito = avg_sh_path(G_saito, 'Saito')\n",
    "avg_star, d_star = avg_sh_path(G_star, 'Star')\n",
    "avg_chain, d_chain= avg_sh_path(G_chain, 'Chain')\n",
    "avg_newman, d_newman = avg_sh_path(G_newman, 'Newman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Graph diameter'] = [d_ours, d_saito, d_star, d_chain, d_newman]\n",
    "data['Average shortest path'] = [avg_ours, avg_saito, avg_star, avg_chain, avg_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Number of connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_cc(G, graph_type):\n",
    "    scc = 0 \n",
    "    wcc = 0 \n",
    "    for C in nx.strongly_connected_components(G):\n",
    "        C = G.subgraph(C)\n",
    "        if len(C)>1: # skip one nodes\n",
    "            scc+=1\n",
    "    for C in nx.weakly_connected_components(G):\n",
    "        C = G.subgraph(C)\n",
    "        if len(C)>1: # skip one nodes\n",
    "            wcc+=1\n",
    "    return scc, wcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scc_ours, wcc_ours = number_cc(G_ours, 'Ours')\n",
    "scc_saito, wcc_saito = number_cc(G_saito, 'Saito')\n",
    "scc_star, wcc_star = number_cc(G_star, 'Star')\n",
    "scc_chain, wcc_chain = number_cc(G_chain, 'Chain')\n",
    "scc_newman, wcc_newman = number_cc(G_newman, 'Newman')\n",
    "\n",
    "data['Number of scc'] = [scc_ours, scc_saito, scc_star, scc_chain, scc_newman]\n",
    "data['Number of wcc'] = [wcc_ours, wcc_saito, wcc_star, wcc_chain, wcc_newman]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv('./Results.csv', mode='a', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
