{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import copy\n",
    "import math\n",
    "import itertools\n",
    "from pulp import LpMaximize, LpProblem, LpStatus, lpSum, LpVariable\n",
    "import time\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load episode set $E$ with the users that retweeted each original tweet in the trace. \n",
    "\n",
    "Each episode $E_{s}$ includes the users that retweeted s, ordered chronologically, as they appear in the trace. The first user in each episode is the user that originally tweeted the tweet, and is denoted by $r_{s}$. Subsequent users in $E_{s}$ are users that retweeted s, either directly from user $r_{s}$ or from another user that appears in $E_{s}$  before them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = 500000\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = pickle.load(open(\"./extracted/E\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in E:\n",
    "    E[tweet] = list(dict.fromkeys(E[tweet]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load episode set $D$ with the users that retweeted each original tweet in the trace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = pickle.load(open(\"./extracted/D\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the set of original tweets denoted by $S$. \n",
    "\n",
    "The set of original tweets is denoted by $S$, where |$S$| = S is the total number of original tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = pickle.load(open(\"./extracted/S\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $U$ set xith unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = pickle.load(open(\"./extracted/U\"+ str(lines) + \".p\", \"rb\"))\n",
    "U = list(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load $M_{ij}$ variables that count number of episodes where the ordered pair (i,j) appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pickle.load(open(\"./extracted/M\"+ str(lines) + \".p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find important quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of unique users N\n",
    "- Number of episodes / original tweets S\n",
    "- Number of active pairs (i,j)\n",
    "\n",
    "For every active pair we have to count the $\\sigma_{ij}$'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(U)\n",
    "print('Number of unique users N =', N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of episodes/original tweets S =',len(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pairs_n = 0 \n",
    "for i in M:\n",
    "    active_pairs_n+=len(M[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of active user pairs in the trace:', active_pairs_n, 'out of the', N*(N-1), 'possible pairs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Constrained-EM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define important functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(obj):\n",
    "    if type(obj) == list:\n",
    "        return [l for L in obj for l in L]\n",
    "    if type(obj) == dict:\n",
    "        return [l for i in obj for l in obj[i].values()]\n",
    "    if type(obj) == defaultdict:\n",
    "        return [l for i in obj for l in obj[i].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(M, Q, s, a, b, r):\n",
    "    for i in M:\n",
    "        for j in M[i]:\n",
    "            e = M[i][j] * s[i][j]\n",
    "            numer = r * (a**e) * ((1-a)**(M[i][j]-e))\n",
    "            denom = r * (a**e) * ((1-a)**(M[i][j]-e)) + (1-r) * (b**e) * ((1-b)**(M[i][j]-e))\n",
    "            Q[i][j] = numer/denom   \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_a(M, Q, s):\n",
    "    a = ((sum([M[i][j] * Q[i][j] * s[i][j]  for i in M for j in M[i]]))\n",
    "        /((sum([M[i][j] * Q[i][j] for i in M for j in M[i]])))) \n",
    "    return(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_b(M, Q, s):\n",
    "    b = ((sum([M[i][j] * (1-Q[i][j]) * s[i][j]  for i in M for j in M[i]]))\n",
    "        /((sum([M[i][j] * (1-Q[i][j]) for i in M for j in M[i]]))))\n",
    "    return(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_r(Q, N, active_pairs_n):\n",
    "    r = (sum([Q[i][j] for i in Q for j in Q[i]]))/(active_pairs_n)      \n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_s(model, M, Q, x, a, b, s, active_pairs):\n",
    "    \"\"\" \n",
    "    This function updates the s_{ij} parameters of the optimization problemm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : PulpModel\n",
    "        Model initialized from Pulp.\n",
    "    M : dict\n",
    "        Dictionary with M_{ij} values tha show how many times an ordered pair (i,j) appears in the trace.\n",
    "    Q : dict\n",
    "        Dictionary with the Q_{ij} values.\n",
    "    W : dict\n",
    "        Dictionary with the coefficients of the problem.\n",
    "    x : dict\n",
    "        Dictionary with the decision variables of the model.\n",
    "    a : float \n",
    "            The true-positive utilization rate.\n",
    "    b : float\n",
    "            The false-positive utilization rate.\n",
    "    s : dict\n",
    "        Dictionary with the updated s_{ij} parameters.\n",
    "    active_pairs : list\n",
    "        Active (i,j) pairs.\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    s : dict\n",
    "        Dictionary with the updated s_{ij} parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    W = defaultdict(dict)\n",
    "    for pair in active_pairs:\n",
    "        i = pair[0]\n",
    "        j = pair[1]\n",
    "        W[i][j] = M[i][j]*((Q[i][j]*math.log(a/(1-a)))+ (1-Q[i][j])*math.log(b/(1-b))) + random.uniform(0,0.001)\n",
    "\n",
    "    s = pulp_solve(model, active_pairs, W, x, s)\n",
    "    return(s, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulp_create_reduct(E, M):\n",
    "    \"\"\" \n",
    "    This function initializes the optimization problem with reduced constraints. Runs the first time\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    model : LpProblem\n",
    "        Pulp model of the problem.\n",
    "    x : Dict\n",
    "        Dictionary with decision variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the maximization problem\n",
    "    model = LpProblem(name=\"constr-newman\", sense=LpMaximize)\n",
    "    \n",
    "    # for each episode in E, each line in constraints_list includes:\n",
    "    # - for each user j in E, the users before them in index 0 and \n",
    "    # - the user itself in index 1\n",
    "    \n",
    "    sij = defaultdict(dict)\n",
    "    constraints_list = []\n",
    "    \n",
    "    for s in D:\n",
    "        for users_list in list(D[s].values()):\n",
    "            index_now = list(D[s].values()).index(users_list)\n",
    "            if index_now == 0:\n",
    "                for u in list(D[s].values())[1]:\n",
    "                    sij[D[s][0][0]][u] = 1\n",
    "            else:\n",
    "                for u in users_list:\n",
    "                    u_before_l = list(D[s].values())[:index_now]\n",
    "                    u_before = [item for sublist in u_before_l for item in sublist]\n",
    "                    if u in u_before: u_before.remove(u)\n",
    "                    constraints_list.append([u_before, u])\n",
    "\n",
    "    len_b = len(constraints_list)\n",
    "\n",
    "    # phase I: delete all constraints that include a pair with sij = 1\n",
    "    \n",
    "    for c in list(constraints_list):\n",
    "        j = c[1]\n",
    "        for i in c[0]:\n",
    "            if i in sij and j in sij[i] and sij[i][j]==1:\n",
    "                constraints_list.remove(c)\n",
    "                break\n",
    "                \n",
    "    # for each episode in $E$, the constraints_dictionary includes:\n",
    "    # - the user j as keys\n",
    "    # - the users that come before them for each constraint that they appear in pos j as values\n",
    "    \n",
    "    constraints_list.sort()\n",
    "    constraints_list = list(constraints_list for constraints_list,_ in itertools.groupby(constraints_list))\n",
    "    constraints_dict = dict()\n",
    "    ind = 0 \n",
    "    for c in constraints_list:\n",
    "            j = c[1]\n",
    "            if j in constraints_dict:\n",
    "                constraints_dict[j].append([c[0],ind])\n",
    "            else:\n",
    "                constraints_dict[j] = []\n",
    "                constraints_dict[j].append([c[0],ind])\n",
    "            ind+=1\n",
    "\n",
    "    # phase II  ----------------------------\n",
    "    \n",
    "    for j in constraints_dict:\n",
    "        for constraint1 in constraints_dict[j]:\n",
    "            for constraint2 in constraints_dict[j]:\n",
    "                if constraint1[1]!=constraint2[1]:\n",
    "                    if set(constraint1[0]).issubset(constraint2[0]):\n",
    "                        if constraint1[0]!=constraint2[0] and collections.Counter(constraint1[0]) != collections.Counter(constraint2[0]): \n",
    "                            if [constraint2[0],j] in constraints_list: # we may have already deleted it\n",
    "                                constraints_list.remove([constraint2[0],j])\n",
    "                    \n",
    "    len_a = len(constraints_list)          \n",
    "    \n",
    "    # add decision variables and create active pairs and sij's randomly \n",
    "    \n",
    "    active_pairs = []\n",
    "    for i in M:\n",
    "        for j in M[i]:\n",
    "            if i not in sij or j not in sij[i]:\n",
    "                active_pairs.append((i,j))\n",
    "                sij[i][j] = random.uniform(0, 1)\n",
    "\n",
    "    active_pairs = list(set(active_pairs))\n",
    "        \n",
    "    x = dict()\n",
    "    x = {f\"{pair[0]}-{pair[1]}\":LpVariable(name=f\"x{pair[0]}-{pair[1]}\", lowBound=0, upBound=0.9999999999999) for pair in active_pairs}\n",
    "    \n",
    "    # add constraints in model\n",
    "    for c in constraints_list: \n",
    "        j = c[1]\n",
    "        tmp = 0\n",
    "        for i in c[0]:\n",
    "            tmp+=x[f\"{i}-{j}\"]\n",
    "        model += (tmp >= 1)\n",
    "    \n",
    "    return model, x, active_pairs, sij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulp_solve(model, active_pairs, W, x, s):\n",
    "    \"\"\" \n",
    "    This function solves the optimization problem with PULP.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : PulpModel\n",
    "        Model initialized from pulp\n",
    "    active_pairs : list\n",
    "        Active pairs of the problem\n",
    "    W : dict\n",
    "        Dictionary with the coefficients of the problem \n",
    "    x : dict\n",
    "        Dictionary with decision variables\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    s : dict\n",
    "        Dictionary with found s_{ij} parameters\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    maxv = max((set(max(list(i.values()) for i in W.values()))))\n",
    "    c = maxv + 0.0001\n",
    "    \n",
    "    # update the objective function\n",
    "    model += lpSum((W[i][j]-c)*x[f\"{i}-{j}\"] for i in W for j in W[i])\n",
    "    # and solve it \n",
    "    status = model.solve()\n",
    "\n",
    "    for var in x.values():\n",
    "        i = var.name.split(\"_\")[0]\n",
    "        i = int(i.split(\"x\")[1])\n",
    "        j = int(var.name.split(\"_\")[1])\n",
    "        s[i][j] = var.value()\n",
    "    \n",
    "    return s\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrainedem(eps, N, M, active_pairs_n):\n",
    "        \"\"\" \n",
    "        This function is the main algorithm for path inference with constraints. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        eps : float\n",
    "            Convergence criterion.\n",
    "        N : int\n",
    "            Number of users in the trace.\n",
    "        M : dict\n",
    "            Dictionary with M_{ij} values tha show how many times an ordered pair (i,j) appears in the trace.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        a : float \n",
    "            The true-positive utilization rate.\n",
    "        b : float\n",
    "            The false-positive utilization rate.\n",
    "        r : float\n",
    "            The uniform prior probability of the existence of an edge in any position between any pair of nodes.\n",
    "        s : dict\n",
    "            Dictionary with s_{ij} values tha show the limiting frequency that \n",
    "            user j reposts directly a post from i when the number of episodes goes to infinity.    \n",
    "        Q : dict\n",
    "            Dictionary with the Q_{ij} values that show the posterior probability of an edge existing between $i$ and $j$.\n",
    "        \"\"\"\n",
    "\n",
    "        iterat = 1\n",
    "\n",
    "        # initialize Q dictionary \n",
    "        Q = defaultdict(dict)\n",
    "\n",
    "        # initialize a, b, r parameters randomly\n",
    "        a = random.uniform(0.5, 1)\n",
    "        b = random.uniform(0, 0.5)\n",
    "        r = random.uniform(0, 1)\n",
    "        \n",
    "        # create pulp model with reduced constraints and variables...')\n",
    "        model, x, active_pairs, s = pulp_create_reduct(E, M)\n",
    "        \n",
    "        # ======================== START algorithm ========================\n",
    "\n",
    "        while True: # repeat until convergence\n",
    "            # Step 1 ==== UPDATE VALUES ====\n",
    "\n",
    "            # 1.1 -- Update Q dictionary\n",
    "            Q = update_Q(M, Q, s, a, b, r)\n",
    "            \n",
    "            # 1.2 -- Update a,b,r,s_{ij} parameters according to Equations\n",
    "            a = update_a(M, Q, s)\n",
    "            b = update_b(M, Q, s)\n",
    "            r = update_r(Q, N, active_pairs_n)\n",
    "\n",
    "            if a ==1: \n",
    "                a = 0.9999999\n",
    "                flag = True\n",
    "            if b ==0: \n",
    "                b = 0.0001\n",
    "                flag = True\n",
    "            \n",
    "            s, W  = update_s(model, M, Q, x, a, b, s, active_pairs)\n",
    "\n",
    "            # Step 2 ==== CHECK CONVERGENCE ====\n",
    "\n",
    "            if iterat > 1:\n",
    "                new_q = np.array(flatten(Q))\n",
    "                new_a = a\n",
    "                new_b = b\n",
    "                cost = sum(s[i][j]*M[i][j]*(Q[i][j]*math.log(a/(1-a))+(1-Q[i][j])*math.log(b/(1-b))) for i in s for j in s[i])\n",
    "                new_cost = cost\n",
    "                changeq = np.linalg.norm(new_q - old_q)  \n",
    "                changea = abs(new_a-old_a)\n",
    "                changeb = abs(new_b-old_b)\n",
    "                changecost = abs(new_cost - old_cost)\n",
    "                if changeq<eps:\n",
    "                    Q_old = copy.deepcopy(Q)\n",
    "                    old_q = np.array(flatten(Q_old))\n",
    "                    old_a = a\n",
    "                    old_b = b\n",
    "                    old_cost = cost        \n",
    "                    break\n",
    "                else: \n",
    "                    Q_old = copy.deepcopy(Q)\n",
    "                    old_q = np.array(flatten(Q_old))\n",
    "                    old_a = a\n",
    "                    old_b = b\n",
    "                    old_cost = cost\n",
    "                    iterat += 1\n",
    "            if iterat == 1:\n",
    "                flag = False\n",
    "                old_q = np.array(flatten(Q))\n",
    "                old_a = a\n",
    "                old_b = b\n",
    "                cost = sum(s[i][j]*M[i][j]*(Q[i][j]*math.log(a/(1-a))+(1-Q[i][j])*math.log(b/(1-b))) for i in s for j in s[i])\n",
    "                old_cost = cost\n",
    "                iterat+=1\n",
    "                \n",
    "        return a, b, r, s, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.001\n",
    "a, b, r, s, Q = constrainedem(eps, N, M, active_pairs_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    pickle.dump(Q, open(\"./extracted/Q_constrained\" + str(lines) + \".p\", \"wb\"))\n",
    "except: \n",
    "    print(\"Unable to write to file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    pickle.dump(s, open(\"./extracted/s_constrained\" + str(lines) + \".p\", \"wb\"))\n",
    "except: \n",
    "    print(\"Unable to write to file\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
